{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP ESPECIAL FUNDAMENTOS DE LA CIENCIA DE DATOS 2024 \n",
    "\n",
    "DATASET: CALIDAD DE AGUA DEL RÍO DE LA PLATA - 2022\n",
    "\n",
    "INTEGRANTES:\n",
    "Abril Valentina Valentina Juarez, Matias Müller Gonzales y Julián Elias Rivero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corroborar si funciona con % o con !\n",
    "\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install fancyimpute\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install seaborn\n",
    "\n",
    "# importar librerias \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fancyimpute import IterativeImputer,KNN\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.read_csv(\"Calidad_de_agua_2022.csv\", sep =\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos el dataset para realizar un vistazo generico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.reset_option('display.max_rows') - \n",
    "# descomentar lo de arriba si quiere que le muestre el dataset truncado!!!!\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora le pedimos un poco de informacion para analizar contexto de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En total tenemos 31 columnas (atributos) y 168 filas (observaciones). Se puede ver que hay ciertas columnas con NULL y que el tipo de datos practicamente es OBJECT exceptuando la primer columna \"orden\" que es de tipo INT64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista veo que tendremos que tratar lo siguiente:\n",
    "1) Hay valores que enves de tener un tipo de dato cuantitativo en el atributo, tienen un string categorico que dice \"no se midio\" o variantes del mismo, por ejemplo en OD(oxigeno disuelto), esto deberia de ser reemplazado NA.\n",
    "2) Hay datos cuantitativos que adelante del valor numerico tienen un string \"<\", como en el caso de las mediciones de los contaminantes en el agua.\n",
    "Podriamos generar un mapa que descriva las observaciones de dicha variable. \n",
    "3) Hay datos cualitativos nominales que indican \"presencia\" o \"ausencia\" de algún compuesto en el agua, estás variables son dicotomicas, seran reemplazados por {0, 1} de acuerdo a su impacto en la muestra. \n",
    "4) Hay datos cualitativos ordinales como \"muy deteriorada\" o \"extremadamente deteriorada\" que hacen referencia al agua de esa zona, seran reemplazados mediante transformacion \"ordinal encoding\" ya que el orden es significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cuantos valores repetidos tiene el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo visto no existe valores repetidos a simple vista."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que empezaremos a modificar el dataset, una buena practica es copiar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset = raw_dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos eliminar columnas que no tienen mucho sentido, como por ejemplo \"orden\" y vamos a eliminar \"año\", ya que todas las observaciones se hicieron en 2022 y no agregan mucha informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset = copy_dataset.drop(\"orden\",axis=1)\n",
    "copy_dataset = copy_dataset.drop(\"año\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver que columnas tienen nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pareciera que existen muy pocos nulos, pero vamos a ver que sucede con el \"no se midió\" , asi que vamos a mostrar algunos ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset[copy_dataset[\"dbo_mg_l\"] == \"no se midió\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pudimos ver hay muchisimos \"no se midió\" que representa NA, entonces vamos a convertir para todas las columnas\n",
    "el \"no se midió\" y las distintas variantes a NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_columnas = copy_dataset.columns\n",
    "\n",
    "for col in lista_columnas:\n",
    "    copy_dataset[col] = copy_dataset[col].replace(['no midieron este día', 'no se midió', 'no se determinó','No se midió',\n",
    "                                                   'no midio la sonda','NA'], pd.NA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez pasado todos los valores a NA vamos a contar cuantos NA tenemos por cada variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset.isna().sum() / copy_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además vemos que ninguna variable tiene más del 50% de valores faltantes, por ende no eliminaremos ninguna variable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminaran todas aquellas observaciones que contengan 14 o mas atributos con valores NA, ya que no nos aportara mucha informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset = copy_dataset.dropna(thresh=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion estamos mostrando aquellas observaciones donde en la columna microcistina_ug_l se encuentran valores que deberian ser numericos, pero son de tipo object, porque hay texto combinado con numeros. Observamos que hay esto sucede en reiteradas ocasiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset[copy_dataset[\"microcistina_ug_l\"] == \" <0.15\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las siguientes columnas fue necesario quitar el string \"<\" y \" <\"(este caracter es el denominado NBSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = [\n",
    "    \"nh4_mg_l\",\n",
    "    \"p_total_l_mg_l\",\n",
    "    \"fosf_ortofos_mg_l\",\n",
    "    \"dbo_mg_l\",\n",
    "    \"dqo_mg_l\",\n",
    "    \"turbiedad_ntu\",\n",
    "    \"hidr_deriv_petr_ug_l\",\n",
    "    \"cr_total_mg_l\",\n",
    "    \"cd_total_mg_l\",\n",
    "    \"clorofila_a_ug_l\",\n",
    "    \"microcistina_ug_l\"\n",
    "]\n",
    "for col in columnas:\n",
    "    copy_dataset[col] = copy_dataset[col].str.strip(\"<\")\n",
    "    copy_dataset[col] = copy_dataset[col].str.strip(\" <\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos la variable \"cd_total_mg_l\" y notaremos que a pesar de quitar el \"<\" el tipo de dato no cambio, sigue siendo de tipo object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset[copy_dataset[\"cd_total_mg_l\"] == \"0.001\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces para esta variable en particular vamos a realizar un mapeo para sustituir el tipo string a tipo entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgl_map = {\n",
    "    \"0.001\":0.001,\n",
    "    \"0.002\":0.002\n",
    "}\n",
    "copy_dataset[\"cd_total_mg_l\"] = copy_dataset[\"cd_total_mg_l\"].map(mgl_map)\n",
    "copy_dataset[\"cd_total_mg_l\"].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la variable calidad_de_agua hicimos una transformacion ordinal encoding, donde cada valor unico de una caracteristica se mapea a un entero, tratando de ser lo mas cuidadoso para preservar el orden natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niveles_deterioro = {\n",
    "    \"Deteriorada\" : 1,\n",
    "    \"Muy deteriorada\" : 2,\n",
    "    \"Extremadamente deteriorada\" : 3\n",
    "}\n",
    "\n",
    "copy_dataset[\"calidad_de_agua\"] = copy_dataset[\"calidad_de_agua\"].map(niveles_deterioro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las siguientes variables continuaremos con un tipo de mapeo dicotomico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapeo_dicotomico = {\n",
    "    \"Ausencia\" : 0,\n",
    "    \"Ausente\" : 0,\n",
    "    \"ausencia\" : 0,\n",
    "    \"presencia\" : 1,\n",
    "    \"Presencia\" : 1\n",
    "}\n",
    "\n",
    "copy_dataset[\"olores\"] = copy_dataset[\"olores\"].map(mapeo_dicotomico)\n",
    "copy_dataset[\"color\"] = copy_dataset[\"color\"].map(mapeo_dicotomico)\n",
    "copy_dataset[\"espumas\"] = copy_dataset[\"espumas\"].map(mapeo_dicotomico)\n",
    "copy_dataset[\"mat_susp\"] = copy_dataset[\"mat_susp\"].map(mapeo_dicotomico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion vamos a cambiar dos valores de la variable \"fecha\", ya que la fecha de la medicion se cargo como \"31/10/0202\" cuando en realidad intuimos que se quiso cargar \"31/10/2022\" debido a que todas las muestras fueron realizadas en dicho año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset[\"fecha\"] = copy_dataset[\"fecha\"].replace(\"31/10/0202\", \"31/10/2022\")\n",
    "copy_dataset[\"fecha\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tratar los NA vamos a operar con todas las columnas que lo posean, a traves de una serie de pasos\n",
    "1_Convertir todas las variables a tipo numerico, exceptuando los NA(aquellos que no puedan convertirse, como los NA, seran convertidos a NAN)\n",
    "2_Calcularemos la mediana para cada estacion del año\n",
    "3_Con la funcion fillna, Asignaremos la mediana de cada estacion a los valores NAN en funcion de la columna a la que pertenezca\n",
    "\n",
    "Decidimos hacer imputacion por mediana y por estacion, para mantener la distribucion de los datos lo mas equilibrada posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = [\n",
    "    \"tem_agua\",\n",
    "    \"tem_aire\",\n",
    "    \"od\",\n",
    "    \"ph\",\n",
    "    \"colif_fecales_ufc_100ml\",\n",
    "    \"escher_coli_ufc_100ml\",\n",
    "    \"enteroc_ufc_100ml\",\n",
    "    \"nitrato_mg_l\",\n",
    "    \"nh4_mg_l\",\n",
    "    \"p_total_l_mg_l\",\n",
    "    \"fosf_ortofos_mg_l\",\n",
    "    \"dbo_mg_l\",\n",
    "    \"dqo_mg_l\",\n",
    "    \"turbiedad_ntu\",\n",
    "    \"hidr_deriv_petr_ug_l\",\n",
    "    \"cr_total_mg_l\",\n",
    "    \"cd_total_mg_l\",\n",
    "    \"clorofila_a_ug_l\",\n",
    "    \"microcistina_ug_l\",\n",
    "    \"ica\"\n",
    "]\n",
    "for col in columnas:\n",
    "    copy_dataset[col] = pd.to_numeric(copy_dataset[col], errors= 'coerce')\n",
    "    \n",
    "    median_verano = copy_dataset.loc[copy_dataset[\"campaña\"] == \"Verano\", col].median()\n",
    "    median_invierno = copy_dataset.loc[copy_dataset[\"campaña\"] == \"invierno\", col].median()\n",
    "    median_otoño = copy_dataset.loc[copy_dataset[\"campaña\"] == \"otoño\", col].median()\n",
    "    median_primavera = copy_dataset.loc[copy_dataset[\"campaña\"] == \"Primavera\", col].median()\n",
    "    \n",
    "    copy_dataset.loc[(copy_dataset['campaña'] == 'Verano') & (copy_dataset[col].isna()), col] = median_verano\n",
    "    copy_dataset.loc[(copy_dataset['campaña'] == 'invierno') & (copy_dataset[col].isna()), col] = median_invierno\n",
    "    copy_dataset.loc[(copy_dataset['campaña'] == 'Primavera') & (copy_dataset[col].isna()), col] = median_primavera\n",
    "    copy_dataset.loc[(copy_dataset['campaña'] == 'otoño') & (copy_dataset[col].isna()), col]=median_otoño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que devolvio una advertencia, lo que indica que para alguna columna no pudo calcular la mediana. indagamos un poco mas y es la columna \"dbo_mg_l\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtramos las muestras donde la campaña es primavera y la columna \"dbo_mg_l\" = Nan\n",
    "primavera_nan = copy_dataset[(copy_dataset['campaña'] == 'Primavera') & (copy_dataset['dbo_mg_l'].isna())]\n",
    "print(primavera_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que para la columna \"dbo_mg_l\" para la campaña Primavera siguen habiendo ocurrencias Nan.\n",
    "la mediana devuelve NaN, significa que no hay suficientes datos válidos en la campaña \"Primavera\" para calcular una mediana, y eso explicaría por qué no podemos reemplazar los valores NaN. En ese caso, podríamos intentar un enfoque alternativo, como usar un valor por defecto o una mediana calculada de otra campaña."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la mediana total de la columna 'dbo_mg_l' sin filtrar por campaña\n",
    "median_total = copy_dataset['dbo_mg_l'].median()\n",
    "# Reemplazar los valores NaN en 'dbo_mg_l' para la campaña 'Primavera' con la mediana total\n",
    "copy_dataset.loc[(copy_dataset['campaña'] == 'Primavera') & (copy_dataset['dbo_mg_l'].isna()), 'dbo_mg_l'] = median_total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verificamos que se reemplazaron los Nan correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset[\"dbo_mg_l\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si estamos en condiciones!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a comenzar con el Análisis Exploratorio de Datos(EDA).\n",
    "\n",
    "Para empezar veamos que nos valores nos dice el HeatMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_correlacion = copy_dataset.drop(columns=[\"sitios\",\"codigo\",\"fecha\",\"campaña\"]).corr()\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.heatmap(matriz_correlacion,vmin=-1.0, vmax=1.0, center=0.0, annot=True, cmap= 'coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista podemos ver que es poco complicado ver entre tantos valores, pero resaltan algunas posibles relaciones, como por ejemplo:\n",
    "\n",
    "Posiblemente exista una relacion entre las variables tem_aire y tem_agua, debido a que el coeficiente de correlacion es de 0.74\n",
    "\n",
    "Tambien podemos ver que posiblemente exista una relacion entre las variables entero_ufc_100ml y escher_coli_ufc_100ml, debido a su coeficiente de correlacion de 0.78\n",
    "\n",
    "Y por ultimo resalta la posible relacion entre las variables ica y calidad_de_agua, aunque parezca raro, se ve que son inversas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tomamos el valor absoluto de las correlaciones, umbralamos las mayores a 0.7\n",
    "correlation_matrix_umbralizada = matriz_correlacion.abs() > 0.6\n",
    "# aprovechamos y sacamos la diagonal\n",
    "np.fill_diagonal(correlation_matrix_umbralizada.values, 0)\n",
    "\n",
    "# e imprimimos la matriz como un heatmap\n",
    "plt.figure(figsize=(16,12));\n",
    "sns.heatmap(correlation_matrix_umbralizada, vmin=0.0, vmax=1.0, center=0.0, annot=True, cmap= 'coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos un describe para ver una serie de caracteristicas descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seteamos la opcion para que el dataset muestre los valores completos y no en notacion cientifica\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustes para que se muestren todas las filas y columnas sin truncamiento\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey, vemos ciertas conductas en algunos indicadores:\n",
    "- en el maximo valor de \"Colif_fecales_ufc_100ml\" (es absurdamente grande) siendo que hasta el 3er cuartil no acumula siquiera la mitad del maximo\n",
    "- en \"Fósforo total\" o \"p_total_l_mg_l\" cuyo valor maximo es de 30.120 mg/L\n",
    "- \"Oxigeno Disuelto\" tiene un minimo bastante chico, y un maximo bastante grande, entre los cuartiles no varia tanto\n",
    "- olores, color, espumas y materia suspendia, fueron mapeadas por lo que no aportan mucho, podemos deducir que en la mayoria de los casos no estan presentes en el agua porque el promedio de cada una esta por debajo del 17%\n",
    "- en \"nh4_mg_l\" o \"Concentración de amonio\"se observa un maximo muy superior a los demas valores\n",
    "- tanto en DBO como en DQO, sus maximos son mas grandes que el valor acumulado hasta el 3er cuartil\n",
    "- La turbiedad en promedio es 34.762 NTU, mientras que el minimo es de 2.5 NTU y el maximo de 130 NTU (bastante turbio jajaj)\n",
    "- La \"Concentración total de cromo\" es bastante baja en promedio, pero el maximo esta muy alejado\n",
    "- La \"Concentración de clorofila\" tiene un desvio estandar muy grande ya que el maximo esta muy alejado\n",
    "\n",
    "Conforme vayamos avanzando, veremos en cuales indicadores deberemos de tomar alguna decision al respecto, si sacar los outliers o darles sentido, acorde a si son un posible error de muestreo, o tienen relevancia en la zona donde se extrajo esa muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinamos la distribucion de \"colif_fecales_ufc_100ml\" mediante BOX PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Creamos BOXPLOT para ver como se distribuyen los datos\n",
    "plt.boxplot(copy_dataset['colif_fecales_ufc_100ml'].dropna(), vert=True, patch_artist=True, boxprops=dict(facecolor=\"lightblue\"))\n",
    "\n",
    "plt.title('Diagrama de Caja para COLIF_FECALES_UFC_100ML')\n",
    "plt.xlabel('Coliformes Fecales en 100ml')\n",
    "plt.ylabel('Unidades expresadas en millones')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay outliers bastantes alejados del resto.. chusmeamos los 5 valores mas grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset.nlargest(5, 'colif_fecales_ufc_100ml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores oscilan entre 700 mil y 4.2 millones, los consideramos extremistas siendo que valores mayores a 20 mil ya indican alta contaminacion fecal, por lo que procederemos a reemplazar aquellos valores superiores a 100 mil por \"100.000\" para intentar equilibrar un poco la distribucion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar valores mayores a 100.000 con 100.000\n",
    "copy_dataset.loc[copy_dataset['colif_fecales_ufc_100ml'] > 100000, 'colif_fecales_ufc_100ml'] = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos el boxplot nuevamente\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(copy_dataset['colif_fecales_ufc_100ml'].dropna(), vert=True, patch_artist=True, boxprops=dict(facecolor=\"lightblue\"))\n",
    "plt.title('Diagrama de Caja para COLIF_FECALES_UFC_100ML')\n",
    "plt.xlabel('Coliformes Fecales en 100ml')\n",
    "plt.ylabel('Unidades expresadas en miles')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve mas lindo ahora... seguimos con otro indicador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miremos \"DQO_MG_L\", que indica la cantidad total de materia orgánica en el agua que puede ser oxidada por medios químicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos el boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(copy_dataset['dqo_mg_l'].dropna(), vert=True, patch_artist=True, boxprops=dict(facecolor=\"lightblue\"))\n",
    "plt.title('BOX PLOT de DQO_MG_L')\n",
    "plt.xlabel('Demanda Química de Oxígeno en miligramos por litro')\n",
    "plt.ylabel('Unidades')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con ayuda del describe y el Box Plot, observamos que hasta el Q3 acumula un total de 50 mg/L, osea hasta el 75%. Hay ciertas zonas donde este indicador es bastante alto y estan alejados del resto de la distribucion, siendo el valor maximo 180 mg/L. Sin embargo, esta dentro de los intervalos posibles que puede tomar este indicador. Utilizaremos una transformación logarítmica (log base 10) para reducir la magnitud de los valores extremadamente grandes (outliers). Esto es útil para manejar distribuciones sesgadas y mejorar la normalidad de los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el IQR (Rango Intercuartílico) para detectar outliers\n",
    "Q1 = copy_dataset['dqo_mg_l'].quantile(0.25)  # Primer cuartil\n",
    "Q3 = copy_dataset['dqo_mg_l'].quantile(0.75)  # Tercer cuartil\n",
    "IQR = Q3 - Q1  # Rango intercuartílico\n",
    "\n",
    "# Definir el límite superior para los outliers\n",
    "limite_superior = Q3 + 1.5 * IQR\n",
    "\n",
    "# Reemplazar los outliers por la transformación logarítmica\n",
    "copy_dataset['dqo_mg_l'] = copy_dataset['dqo_mg_l'].apply(\n",
    "    lambda x: np.log10(x) if x > limite_superior and x > 0 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos el boxplot nuevamente\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(copy_dataset['dqo_mg_l'].dropna(), vert=True, patch_artist=True, boxprops=dict(facecolor=\"lightblue\"))\n",
    "plt.title('BOX PLOT de DQO_MG_L')\n",
    "plt.xlabel('Demanda Química de Oxígeno en miligramos por litro')\n",
    "plt.ylabel('Unidades')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se aprecia mejor, continuemos.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinemos la Turbiedad en el agua mediante un histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(copy_dataset['turbiedad_ntu'], bins=20, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Títulos y etiquetas\n",
    "plt.title('Histograma de la Turbiedad del Agua', fontsize=16)\n",
    "plt.xlabel('Turbidez (NTU)', fontsize=14)\n",
    "plt.ylabel('Frecuencia', fontsize=14)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la mayoria de los datos de distribuyen entre 15 y 30 NTU. Una turbiedad mayor a 100 NTU podría ser señal de contaminación por materiales suspendidos, sedimentos o contaminación industrial, por lo que podria ser posible para zonas directamente afectadas por el humano o intensas lluvias. \n",
    "\n",
    "No eliminaremos ni reemplazaremos ningun valor extremo, ya que esos 2 lugares que superan los 100 NTU podrian ser lugares que realmente estan siendo afectados, y no un error en la medicion de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ver que pasa con el indicador \"CR_TOTAL_MG_L\", La concentración de cromo en el agua (cromo es un metal pesado que puede ser tóxico para los seres humanos y los ecosistemas acuáticos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset[\"cr_total_mg_l\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el valor mas frecuente es 0.005 mg/L. Relativamente bajo en comparación con los límites de seguridad establecidos para el agua potable, lo que indicaría que no es una concentración peligrosa desde el punto de vista de la salud humana.\n",
    "\n",
    "Tambien notamos una gran diferencia de rangos, por un lado 0.005 y por otro lado 12. \n",
    "\n",
    "En el contexto del Río de la Plata, donde el cromo puede estar presente debido a actividades industriales, valores como 0.5 mg/L aún se considerarían elevados\n",
    "\n",
    "Reemplazemos aquellas ocurrencias mayores a 0.5, por este valor para intentar acomodar un poco los rangos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar los valores mayores a 0.5 mg/L, por 0.5.\n",
    "copy_dataset['cr_total_mg_l'] = copy_dataset['cr_total_mg_l'].apply(lambda x: 0.5 if x > 0.5 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset[\"cr_total_mg_l\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora si... prosigamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Creamos BOXPLOT para ver como se distribuyen los datos\n",
    "plt.boxplot(copy_dataset['clorofila_a_ug_l'].dropna(), vert=True, patch_artist=True, boxprops=dict(facecolor=\"lightblue\"))\n",
    "\n",
    "plt.title('Diagrama de Caja para clorofila_a_ug_l')\n",
    "plt.xlabel('Clorofila A en microgramos por litro (µg/L)')\n",
    "plt.ylabel('Unidades')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el BOX PLOT denota una distribucion sesgada a derecha, hay extremos demasiados altos. El maximo es aprox 6000 ug/L\n",
    "\n",
    "Muy alto (>50 µg/L): Eutrofización grave, posible floración algal, agua no apta para consumo o recreación sin tratamiento.\n",
    "\n",
    "Reemplazemos aquellos valores mayores a 100 ug/l por 100 ug/l, lo que seguira representando un valor alto para este indicador segun las fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar los valores mayores a 100 por 100 en la columna 'clorofila_a_ug_l'\n",
    "\n",
    "copy_dataset['clorofila_a_ug_l'] = copy_dataset['clorofila_a_ug_l'].apply(\n",
    "    lambda x: 100 if x > 100 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Creamos BOXPLOT para ver como se distribuyen los datos\n",
    "plt.boxplot(copy_dataset['clorofila_a_ug_l'].dropna(), vert=True, patch_artist=True, boxprops=dict(facecolor=\"lightblue\"))\n",
    "\n",
    "plt.title('Diagrama de Caja para clorofila_a_ug_l')\n",
    "plt.xlabel('Clorofila A en microgramos por litro (µg/L)')\n",
    "plt.ylabel('Unidades')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora se ve mejor... empezemos a desarrollar alguna posible hipotesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una manera de resumir todas las posibles relaciones es construyendo una matriz de correlación, donde presentemos todos los valores de correlación entre todos los posibles pares de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = copy_dataset.corr(numeric_only=True)\n",
    "# tomamos el valor absoluto de las correlaciones, umbralamos las mayores a 0.6\n",
    "correlation_matrix_umbralizada = correlation_matrix.abs() > 0.6\n",
    "# aprovechamos y sacamos la diagonal\n",
    "np.fill_diagonal(correlation_matrix_umbralizada.values, 0)\n",
    "\n",
    "# e imprimimos la matriz como un heatmap\n",
    "plt.figure(figsize=(16,12));\n",
    "sns.heatmap(correlation_matrix_umbralizada, vmin=0.0, vmax=1.0, center=0.0, annot=True, cmap= 'coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos las siguientes potenciales relaciones lineales: \n",
    "- temperatura del agua y temperatura del aire: Esta no nos aporta nada interesante.\n",
    "- ICA y colif_fecales_ufc_100ml: Calidad del agua vs contaminacion fecal de coliflores.\n",
    "- enteroc_ufc_100ml y escher_coli_ufc_100ml: indicadores microbiológicos que reflejan la contaminación fecal en muestras de agua. Cada uno representa un grupo diferente de bacterias.\n",
    "- dbo_mg_l y fosf_ortofos_mg_l: Altos niveles de fosfatos suelen estar correlacionados con un aumento de la materia orgánica disponible, lo que incrementa la DBO. Sin embargo, la relación no siempre es lineal, ya que la DBO también depende de otros factores\n",
    "- ICA y calidad del agua: no nos aporta informacion valiosa. es comun pensar una relacion entre ellos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora analicemos una a una, utilizando un scatter plot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primero el ICA vs COLIF_FECALES_UFC_100ML. Aplicamos normalizacion min-max para ajustar escala y grafiquemos un scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Crear el objeto de normalización\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizar las columnas\n",
    "copy_dataset['ica_normalizado'] = scaler.fit_transform(copy_dataset[['ica']])\n",
    "copy_dataset['colif_fecales_normalizado'] = scaler.fit_transform(copy_dataset[['colif_fecales_ufc_100ml']])\n",
    "\n",
    "# Crear scatter plot con datos normalizados\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(copy_dataset['colif_fecales_normalizado'], copy_dataset['ica_normalizado'], alpha=0.6, c='green', edgecolors='k')\n",
    "plt.title('Relación entre ICA Normalizado y Coliformes Fecales Normalizado')\n",
    "plt.xlabel('Coliformes Fecales (UFC/100ml) Normalizado')\n",
    "plt.ylabel('Índice de Calidad del Agua (ICA) Normalizado')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se ve cierta tendencia a que a valores mas altos del \"indice de calidad de agua\", valores mas bajos de coliformes fecales. Sin embargo, la correlacion no es tan significativa y los datos estan bastante dispersos, no podemos asegurar una relacion lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos que pasa con \"dbo_mg_l\" vs \"fosf_ortofos_mg_l\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(copy_dataset['dbo_mg_l'], copy_dataset['fosf_ortofos_mg_l'], alpha=0.6, c='purple', edgecolors='k')\n",
    "plt.title('Relación entre DBO y Fosfatos Ortofosfatos')\n",
    "plt.xlabel('DBO (mg/L)')\n",
    "plt.ylabel('Fosfatos Ortofosfatos (mg/L)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examinamos que valor arrojo el coeficiente de correlacion\n",
    "correlacion = copy_dataset[['dbo_mg_l', 'fosf_ortofos_mg_l']].corr()\n",
    "print(\"Correlación entre DBO y Fosfatos Ortofosfatos:\")\n",
    "print(correlacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No podemos asumir una relacion lineal clara, ya que se puede notar cierta tendencia ascendente pero los datos siguen bastante dispersos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como del heapmap no pudimos extraer algo solido, nos centraremos en principio en el ICA (Indice de Calidad del Agua) ya que es una medida utilizada para evaluar la calidad general del agua de manera sencilla, basándose en varios parámetros como la concentración de contaminantes, la turbidez, la oxigenación, el pH, entre otros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos en el siguiente histograma, como se distribuyen los diferentes valores del ICA en todas las observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(copy_dataset['ica'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribución del Índice de Calidad del Agua (ICA)', fontsize=14)\n",
    "plt.xlabel('ICA', fontsize=12)\n",
    "plt.ylabel('Frecuencia', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el grafico vemos que los valores que mas se repiten de ICA oscilan entre 35 y 45 (siendo 40 el que mas se repite) lo que indicaria una prevalencia de media a baja calidad de agua. Tambien se observa que hay 2 valores que se alejan bastante de los demas, uno mayor a 70 y el otro menor a 30.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En principio, uno pensaria que el ICA deberia de ser peor en condiciones climaticas de mayor temperatura, osea valores mas bajos, ya que la temperatura del agua se eleva y trae consigo ciertos fenomenos como la elevacion de los niveles de contaminantes orgánicos, la reduccion de la cantidad de oxígeno disuelto en el agua o incluso el aumento de los niveles de clorofila, afectando los valores de turbidez.\n",
    "\n",
    "Esto podria ser tomado como una primera hipotesis inicial, en la que comprobaremos si el ICA en Verano, es peor que en las otras estaciones, debido al aumento de precipitaciones, humedad, mas calor, etc. ¿Sera asi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinaremos los valores del ICA para las 4 campañas o fechas del dataset, que corresponden a las 4 estaciones del año: Verano, Otoño, Invierno y Primavera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "# iteracion donde por cada una de las 4 fechas de muestreo, muestra la variacion del ICA\n",
    "for fecha in copy_dataset['fecha'].unique():\n",
    "    data_fecha = copy_dataset[copy_dataset['fecha'] == fecha]\n",
    "    plt.plot(data_fecha['ica'], label=f'Fecha: {fecha}')\n",
    "\n",
    "plt.xlabel('Índice de Muestra')\n",
    "plt.ylabel('ICA')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Fechas')\n",
    "plt.title('Valores de ICA por Fecha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar, que hay una tendencia de menores niveles de ICA en la campaña \"Invierno\" (23/08/2022). Los 3 valores mas chicos que toma este indicador, estan presentes en esta estacion por alguna razon, lo que parece extraño, porque en inicio creiamos lo opuesto. Ademas en verano vemos un pico bastante alto que podria ser un error de medicion o alguna zona en la que raramente ese valor es muy alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustes para que se muestren todas las filas y columnas sin truncamiento\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LA SIGUIENTE FUNCION, OPERA POR CADA OBSERVACION DEL DATASET, AGREGANDO A LA LISTA \"INDICES_FILTRADOS\" AQUELLAS MUESTRAS HECHAS EN INVIERNO DONDE EL \"ICA\" SEA MENOR EN COMPARACION CON LAS OTRAS 3 CAMPAÑAS, PARA ESA MISMA OBSERVACION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_ica_minimo(df):\n",
    "    # Inicializar una lista para guardar los índices de las filas que cumplen la condición\n",
    "    indices_filtrados = []\n",
    "    \n",
    "    # Iterar sobre las filas de la campaña \"invierno\"\n",
    "    for idx, row in df[df['campaña'] == 'invierno'].iterrows():\n",
    "        # Obtener el valor de ICA para la fila actual\n",
    "        ica_invierno = row['ica']\n",
    "        \n",
    "        # Filtrar las filas con la misma observación en otras campañas\n",
    "        otras_campañas = df[(df['sitios'] == row['sitios']) & (df['campaña'] != 'invierno')]\n",
    "        \n",
    "        # Obtener el valor mínimo de ICA de las otras campañas\n",
    "        min_ica_otra_campaña = otras_campañas['ica'].min()\n",
    "        \n",
    "        # Si el ICA en invierno es menor que el mínimo de las otras campañas, agregar el índice a la lista\n",
    "        if ica_invierno < min_ica_otra_campaña:\n",
    "            indices_filtrados.append(idx)\n",
    "    \n",
    "    # Devolver el indice de las filas filtradas\n",
    "    return indices_filtrados\n",
    "\n",
    "# Llamar a la función con la copia del dataset\n",
    "resultado = filtrar_ica_minimo(copy_dataset)\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VEMOS QUE 21 de 37 muestras totales hechas en invierno, el \"ICA\" es mas bajo en comparacion a las demas estaciones. un 56% lo que es bastante peculiar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procederemos a ver en que sitios el ICA es mas bajo para la campaña invierno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset[copy_dataset['campaña'] == 'invierno'].nsmallest(5, 'ica')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El ICA oscila entre 23 y 32, lo que es muy bajo.\n",
    "- En todas la calidad del agua esta extremadamente deteriorada.\n",
    "- En las primeras 2 observaciones hay presencia de olores y colores en el agua.\n",
    "- La turbidez en todos los casos es mayor a 11, lo que es un peligroso para la salud.\n",
    "- Para la 2da observacion la concentracion total de cromo es elevadisima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinemos el sitio para el cual el ICA es mas bajo, \"Diagonal 66 (descarga cloaca)\", para las 4 campañas diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buscamos las 4 observaciones del mismo sitio\n",
    "copy_dataset[copy_dataset['sitios'] == 'Diagonal 66 (descarga cloaca)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las 4 campañas, el valor mas bajo de ICA para este lugar en concreto, es en invierno. Veremos que atributos son los mas impactantes para esta campaña a ver si podemos deducir algo.\n",
    "Se ve que es un lugar bastante contaminado ya que cuenta con la presencia de olor, color, espuma y materia suspendida en el agua, pero ¿Por que el ICA nos da mas bajo en invierno¿ ¿Sera que en esta estacion ocurre algo en la zona que provoca esta anomalia? de verificar esto, no olvidar que 21 de 37 muestras dieron un indice de calidad de agua menor en invierno que en las otras estaciones, un 56%, lo que probablemente signifique que pueda haber una relacion entre el ICA y las temperaturas mas bajas, para este dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificaremos si hay una relacion entre las temperaturas y el ICA.\n",
    "Cálculo del p-valor para las correlaciones entre \"tem_agua\" y \"ICA\", y entre \"tem_aire\" y \"ICA\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos mediante el metodo MIN-MAX\n",
    "copy_dataset['tem_agua_norm'] = (copy_dataset['tem_agua'] - copy_dataset['tem_agua'].min()) / (copy_dataset['tem_agua'].max() - copy_dataset['tem_agua'].min())\n",
    "copy_dataset['tem_aire_norm'] = (copy_dataset['tem_aire'] - copy_dataset['tem_aire'].min()) / (copy_dataset['tem_aire'].max() - copy_dataset['tem_aire'].min())\n",
    "copy_dataset['ica_norm'] = (copy_dataset['ica'] - copy_dataset['ica'].min()) / (copy_dataset['ica'].max() - copy_dataset['ica'].min())\n",
    "\n",
    "# Correlación y p-valor entre \"tem_agua\" y \"ICA\"\n",
    "corr_tem_agua_ica, p_val_agua_ica = pearsonr(copy_dataset['tem_agua_norm'], copy_dataset['ica_norm'])\n",
    "print(f\"Correlación entre Temperatura del Agua y ICA: {corr_tem_agua_ica}\")\n",
    "print(f\"P-valor entre Temperatura del Agua y ICA: {p_val_agua_ica}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque la correlación es baja, la relación entre la temperatura del agua y el ICA es significativa desde el punto de vista estadístico, el P-valor arroja un resultado menor a 0.05. Sin embargo, dado que el coeficiente de correlación es débil, puede ser útil investigar si otros factores están afectando el ICA y si hay interacciones entre las variables involucradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definicion de datasets y variables a trabajar \n",
    "\n",
    "invierno = copy_dataset[copy_dataset['campaña'] == 'invierno']\n",
    "verano = copy_dataset[copy_dataset['campaña'] == 'Verano']\n",
    "\n",
    "variables = [ \"turbiedad_ntu\", \"color\", \"olores\", \"mat_susp\", \"espumas\",\n",
    "             \"tem_agua\", \"tem_aire\",\n",
    "             \"od\", \"ph\",  'escher_coli_ufc_100ml',\n",
    "             'colif_fecales_ufc_100ml',\n",
    "            \"enteroc_ufc_100ml\", \"nh4_mg_l\", \"p_total_l_mg_l\", \n",
    "            \"fosf_ortofos_mg_l\", \"dbo_mg_l\", 'dqo_mg_l', \"cr_total_mg_l\",\n",
    "            'hidr_deriv_petr_ug_l',  'clorofila_a_ug_l', 'microcistina_ug_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficamos para ver los outliers\n",
    "\n",
    "# BOXPLOT Invierno - para ver outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "invierno[variables].boxplot(rot=90)\n",
    "plt.title('Boxplot - Invierno')\n",
    "plt.show()\n",
    "\n",
    "# BOXPLOT Verano - para ver outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "verano[variables].boxplot(rot=90)\n",
    "plt.title('Boxplot - Verano')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los outliers mas extremos estan en los indicadores de contaminacion fecal, aplicaremos transformacion logaritmica en estos 3 para equilibrar la distribucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar logaritmo base 10 con ajuste\n",
    "copy_dataset['colif_fecales_ufc_100ml'] = np.log10(copy_dataset['colif_fecales_ufc_100ml'] + 1)\n",
    "copy_dataset['escher_coli_ufc_100ml'] = np.log10(copy_dataset['escher_coli_ufc_100ml'] + 1)\n",
    "copy_dataset['enteroc_ufc_100ml'] = np.log10(copy_dataset['enteroc_ufc_100ml'] + 1)\n",
    "\n",
    "#hago lo mismo que antes\n",
    "\n",
    "# definicion de datasets y variables a trabajar \n",
    "\n",
    "invierno = copy_dataset[copy_dataset['campaña'] == 'invierno']\n",
    "verano = copy_dataset[copy_dataset['campaña'] == 'Verano']\n",
    "\n",
    "variables = [ \"turbiedad_ntu\", \"color\", \"olores\", \"mat_susp\", \"espumas\",\n",
    "             \"tem_agua\", \"tem_aire\",\n",
    "             \"od\", \"ph\",  'escher_coli_ufc_100ml',\n",
    "             'colif_fecales_ufc_100ml',\n",
    "            \"enteroc_ufc_100ml\", \"nh4_mg_l\", \"p_total_l_mg_l\", \n",
    "            \"fosf_ortofos_mg_l\", \"dbo_mg_l\", 'dqo_mg_l', \"cr_total_mg_l\",\n",
    "            'hidr_deriv_petr_ug_l',  'clorofila_a_ug_l', 'microcistina_ug_l']\n",
    "\n",
    "# BOXPLOT Invierno - para ver outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "invierno[variables].boxplot(rot=90)\n",
    "plt.title('Boxplot - Invierno')\n",
    "plt.show()\n",
    "\n",
    "# BOXPLOT Verano - para ver outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "verano[variables].boxplot(rot=90)\n",
    "plt.title('Boxplot - Verano')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora si."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA para ambas estaciones\n",
    "variables = [ \"turbiedad_ntu\", \"color\", \"olores\", \"mat_susp\", \"espumas\",\n",
    "             \"tem_agua\", \"tem_aire\",\n",
    "             \"od\", \"ph\",  'escher_coli_ufc_100ml',\n",
    "             'colif_fecales_ufc_100ml',\n",
    "            \"enteroc_ufc_100ml\", \"nh4_mg_l\", \"p_total_l_mg_l\", \n",
    "            \"fosf_ortofos_mg_l\", \"dbo_mg_l\", 'dqo_mg_l', \"cr_total_mg_l\",\n",
    "            'hidr_deriv_petr_ug_l',  'clorofila_a_ug_l', 'microcistina_ug_l']\n",
    "\n",
    "# Separar dataset\n",
    "X_invierno = invierno[variables]\n",
    "X_verano = verano[variables]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(copy_dataset[variables])  # Ajustar en todo el conjunto\n",
    "X_invierno_scaled = scaler.transform(X_invierno)\n",
    "X_verano_scaled = scaler.transform(X_verano)\n",
    "\n",
    "# PCA para invierno\n",
    "pca_invierno = PCA(n_components=2)\n",
    "principal_invierno = pca_invierno.fit_transform(X_invierno_scaled)\n",
    "\n",
    "# PCA para verano\n",
    "pca_verano = PCA(n_components=2)\n",
    "principal_verano = pca_verano.fit_transform(X_verano_scaled)\n",
    "\n",
    "\n",
    "# Scatter plot para invierno\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "scatter1 = plt.scatter(principal_invierno[:,0],principal_invierno[:,1],c = invierno['ica'],cmap=\"viridis\")\n",
    "\n",
    "cbar = plt.colorbar(scatter1)\n",
    "cbar.set_label(\"Calidad del Agua\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.title('Proyección del conjunto a 2 dimensiones - invierno')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot para las variables quimicas\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "scatter2 = plt.scatter(principal_verano[:,0],principal_verano[:,1],c = verano['ica'],cmap=\"viridis\")\n",
    "\n",
    "cbar = plt.colorbar(scatter2)\n",
    "cbar.set_label(\"Calidad del Agua\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.title('Proyección del conjunto a 2 dimensiones - verano')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Ver porcentaje de varianza explicada\n",
    "print(\"Varianza explicada por los componentes principales (invierno):\", pca_invierno.explained_variance_ratio_)\n",
    "print(\"Varianza explicada por los componentes principales (verano):\", pca_verano.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el gráfico de barras PC1 invierno\n",
    "plt.bar(variables, pca_invierno.components_[0])\n",
    "plt.ylim(-0.6,0.8)\n",
    "# Agregar etiquetas a los ejes\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"Peso\")\n",
    "# Agregar un título al gráfico\n",
    "plt.title(\"Invierno\")\n",
    "plt.xticks(rotation=90)  # Rotar las etiquetas del eje x para mejor visualización\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n",
    "\n",
    "# gráfico de barras PC2 invierno\n",
    "plt.bar(variables, pca_invierno.components_[1])\n",
    "plt.ylim(-0.6,0.8)\n",
    "plt.xlabel(\"PC2\")\n",
    "plt.ylabel(\"Peso\")\n",
    "plt.title(\"Invierno\")\n",
    "plt.xticks(rotation=90)  \n",
    "plt.show()\n",
    "\n",
    "# gráfico de barras PC1 verano\n",
    "plt.bar(variables, pca_verano.components_[0])\n",
    "plt.ylim(-0.6,0.8)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"Peso\")\n",
    "plt.title(\"Verano\")\n",
    "plt.xticks(rotation=90)  \n",
    "plt.show()\n",
    "\n",
    "# gráfico de barras\n",
    "plt.bar(variables, pca_verano.components_[1])\n",
    "plt.ylim(-0.6,0.8)\n",
    "plt.xlabel(\"PC2\")\n",
    "plt.ylabel(\"Peso\")\n",
    "plt.title(\"Verano\")\n",
    "plt.xticks(rotation=90)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipótesis: la presencia de olor, color y espuma (las 3 dicotomicas) se relaciona con un menor índice de calidad del agua (ICA) o calidad del agua(categorica). Intentaremos deducir si existe una relacion entre estas variables, insistiendo sobre el indice de calidad de agua, a ver si le podemos sacar mejor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un gráfico de barras para comparar las medias de ICA según las condiciones visuales\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Gráfico para comparar las medias de ICA según espumas, olores y color\n",
    "sns.barplot(x='variable', y='ica', hue='valor', \n",
    "            data=pd.melt(copy_dataset[['ica', 'espumas', 'olores', 'color']],\n",
    "             id_vars=['ica'], value_vars=['espumas', 'olores', 'color'], var_name='variable', value_name='valor'))\n",
    "\n",
    "plt.title(\"Comparación de medias de ICA según condiciones visuales (espumas, olores, color)\")\n",
    "plt.ylabel(\"Índice de Calidad del Agua (ICA)\")\n",
    "plt.xlabel(\"Condición Visual\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EN 0 SERIA LA MEDIA DE \"ICA\" SIN LA PRESENCIA DE ESAS VARIABLES EN LA MUESTRA.\n",
    "\n",
    "EN 1 SERIA LA MEDIA DE \"ICA\" CON LA PRESENCIA DE ESAS VARIABLES EN LA MUESTRA\n",
    "\n",
    "VEMOS QUE LA MAS CAMBIANTE ES CON O SIN ESPUMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como trabajamos con variables dicotómicas (olor, color, espuma) para confirmar que existe una relación entre cada una de estas variables y la calidad del agua (que es categórica), tuvimos que hacer varias pruebas de Chi cuadrado de independencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Crear una tabla de contingencia\n",
    "contingency_table = pd.crosstab(index=copy_dataset['olores'], columns=copy_dataset['calidad_de_agua'])\n",
    "\n",
    "# Realizar la prueba de chi-cuadrado\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Estadístico chi-cuadrado: {chi2}\")\n",
    "print(f\"Valor p: {p}\")\n",
    "print(f\"Grados de libertad: {dof}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Crear una tabla de contingencia\n",
    "contingency_table = pd.crosstab(index=copy_dataset['color'],\n",
    "                                columns=copy_dataset['calidad_de_agua'])\n",
    "\n",
    "# Realizar la prueba de chi-cuadrado\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Estadístico chi-cuadrado: {chi2}\")\n",
    "print(f\"Valor p: {p}\")\n",
    "print(f\"Grados de libertad: {dof}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Crear una tabla de contingencia\n",
    "contingency_table = pd.crosstab(index=copy_dataset['espumas'], columns=copy_dataset['calidad_de_agua'])\n",
    "\n",
    "# Realizar la prueba de chi-cuadrado\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Estadístico chi-cuadrado: {chi2}\")\n",
    "print(f\"Valor p: {p}\")\n",
    "print(f\"Grados de libertad: {dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las 3 pruebas de Chi cuadrado obtuvimos p valores mayores a 0.05, indica que no hay suficiente evidencia para rechazar la hipótesis nula. Esto sugiere que no hay una relación estadísticamente significativa entre las variables olor, color y espuma y los niveles de calidad analizados.\n",
    "\n",
    "La decisión de rechazar la hipótesis depende de los resultados obtenidos y del valor p. En este caso, dado que tanto el test de independencia como el ANOVA no mostraron evidencia significativa (con valores p mayores a 0.05), parece que no se puede concluir que exista una relación significativa entre las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos que pasa en OXIGENO DISUELTO, ya que su valor maximo es bastante alto en comparacion al resto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Creamos BOXPLOT\n",
    "plt.boxplot(copy_dataset['od'].dropna(), vert=True, patch_artist=True, boxprops=dict(facecolor=\"lightblue\"))\n",
    "\n",
    "plt.title('Diagrama de Caja para la columna OD')\n",
    "plt.xlabel('OD')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de analizar este boxplot podemos encontrarnos con ciertos outliers, 2 por encima del limite superior y 4 por debajo del limite inferior. vemos que la mediana (Q2) es casi 7, que el Q1 y Q3 estan bastante cerca de de ese valor, lo que indicaria una distribucion bastante equilibrada entre los cuartiles. \n",
    "Sabemos que los valores optimos para \"OD\" oscilan entre 5 y 9. Veremos en que lugar se encuentra ese outlier en 17.5, ya que valores superiores a 10 mg/L son raros y, si aparecen, suelen deberse a procesos de fotosíntesis intensa en ciertas zonas, pero pueden estar acompañados de fluctuaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset[copy_dataset[\"od\"] == 17.610]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El sitio se llama \"costanera Hudson Calle 63\", que ademas de niveles altisimos de Oxigeno Disuelto, presenta una alta contaminacion fecal, una moderada contaminacion por presencia de nitratos en el agua (influencia de actividades humanas, como la agricultura o las aguas residuales) y una turbiedad sumamente elevada, que podria estar influenciada directamente por el \"OD\"\n",
    "\n",
    "Investigando un poco mas en los medios, vemos que Hudson esta marcado por una gran presencia de humedales los cuales ayudan a atrapar el carbono del aire, lo cual es muy importante para mitigar el cambio climatico y albergar biodiversidad. En consecuencia, el nivel de OD de 17 mg/L podría estar relacionado con un efecto de fotosíntesis intensa. Sin embargo, es ideal medir en diferentes momentos del día, ya que el oxígeno disuelto puede variar entre el día y la noche debido a la fotosíntesis y la respiración de los organismos acuáticos.\n",
    "\n",
    "En conclusion, el outlier examinado podria no ser un error de medicion, en este caso, y si un claro ejemplo del impacto de los humedales\n",
    "\n",
    "Los humedales pueden crear condiciones excepcionales para el aumento de oxígeno disuelto, esta justificación añade una capa importante de contexto ecológico a los datos, podriamos seguir explayando un poco mas a partir de esto\n",
    "\n",
    "¿Hay una relacion directa entre los humedales y el oxigeno disuelto en las mediciones? ¿A que otros indicadores puede afectar la presencia de estos?\n",
    "\n",
    "A este hecho sumarle los desastres causados por los megaemprendimientos y los incendios forestales en los humedales, repercurtiendo en otros indicadores como la turbiedad, el ph, la presencia de nitrato, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filtraremos las 5 muestras con mayor \"OXIGENO DISUELTO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las 5 filas con los valores más altos en la columna \"OD\"\n",
    "top_5_od = copy_dataset.nlargest(5, 'od')\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(top_5_od)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vemos que el ph en las 5 muestras oscila entre 8.3 y 10 lo que indicaria un leve a grave desequilibrio en el agua, producto de algun factor externo.\n",
    "- Encontramos otra coincidencia. \"Puerto Trinidad calle 47\" y \"Costanera Hudson calle 63\" ambos estan en la localidad de Berazategui, y ambos lugares estan siendo victima de daños en los humedales desde hace unos años. La Concentración de nitratos en miligramos por litro (mg/L) en ambos lugares es bastante alta. El DBO y DQO son altisimos tambien.\n",
    "- En \"Puerto Trinidad calle 47\" hay una marcada contaminacion fecal y alta presencia de formas de fósforo en el agua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el humano con sus inventos esta impactando severamente en la naturaleza de los humedales y su poder para manter el equilibrio y calidad del agua. Sumado a los incendios forestales desatados intencionalmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos gráficos de dispersión (scatter plot) para analizar la relación entre el OD y las variables que sospechamos que pueden estar relacionadas, como PH, DBO, DQO o turbiedad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metodo de normalizacion MIN-MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizar las columnas 'OD','TURBIEDAD', 'ph', 'dbo' y 'dqo'. método de normalización min-max\n",
    "copy_dataset['od_normalizado'] = (copy_dataset['od'] - copy_dataset['od'].min()) / (copy_dataset['od'].max() - copy_dataset['od'].min())\n",
    "copy_dataset['turbiedad_normalizado'] = (copy_dataset['turbiedad_ntu'] - copy_dataset['turbiedad_ntu'].min()) / (copy_dataset['turbiedad_ntu'].max() - copy_dataset['turbiedad_ntu'].min())\n",
    "copy_dataset['ph_normalizado'] = (copy_dataset['ph'] - copy_dataset['ph'].min()) / (copy_dataset['ph'].max() - copy_dataset['ph'].min())\n",
    "copy_dataset['dbo_normalizado'] = (copy_dataset['dbo_mg_l'] - copy_dataset['dbo_mg_l'].min()) / (copy_dataset['dbo_mg_l'].max() - copy_dataset['dbo_mg_l'].min())\n",
    "copy_dataset['dqo_normalizado'] = (copy_dataset['dqo_mg_l'] - copy_dataset['dqo_mg_l'].min()) / (copy_dataset['dqo_mg_l'].max() - copy_dataset['dqo_mg_l'].min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos grafico de dispersion para \"od y turbiedad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(copy_dataset['turbiedad_normalizado'], copy_dataset['od_normalizado'], color='blue')\n",
    "plt.xlabel('Turbiedad')\n",
    "plt.ylabel('Oxígeno Disuelto (OD)')\n",
    "plt.title('Relación entre OD y TURBIEDAD')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la correlación de Pearson entre las dos columnas\n",
    "correlacion = copy_dataset['turbiedad_normalizado'].corr(copy_dataset['od_normalizado'])\n",
    "print(f\"Coeficiente de Correlación de Pearson: {correlacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVANDO EL GRAFICO Y USANDO EL COEFICIENTE DE PEARSON: Correlación muy débil o inexistente. Casi no hay relación lineal entre las variables \"OD\" y \"turbiedad\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hacemos grafico de dispersion para \"od y ph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(copy_dataset['ph_normalizado'], copy_dataset['od_normalizado'], color='red')\n",
    "plt.xlabel('ph')\n",
    "plt.ylabel('Oxígeno Disuelto (OD)')\n",
    "plt.title('Relación entre OD y PH')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la correlación de Pearson entre las dos columnas\n",
    "correlacion = copy_dataset['ph_normalizado'].corr(copy_dataset['od_normalizado'])\n",
    "print(f\"Coeficiente de Correlación de Pearson: {correlacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVANDO EL GRAFICO Y USANDO EL COEFICIENTE DE PEARSON: Correlación moderada. Existe una relación lineal clara, aunque no tan intensa entre las variables \"OD\" y \"PH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos grafico de dispersion entre \"od y DBO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(copy_dataset['dbo_normalizado'], copy_dataset['od_normalizado'], color='black')\n",
    "plt.xlabel('DBO')\n",
    "plt.ylabel('Oxígeno Disuelto (OD)')\n",
    "plt.title('Relación entre OD y DBO')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la correlación de Pearson entre las dos columnas\n",
    "correlacion = copy_dataset['dbo_normalizado'].corr(copy_dataset['od_normalizado'])\n",
    "print(f\"Coeficiente de Correlación de Pearson: {correlacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVANDO EL GRAFICO Y USANDO EL COEFICIENTE DE PEARSON: Correlación muy débil o inexistente. Casi no hay relación lineal entre las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos grafico de dispersion entre \"od y dqo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(copy_dataset['dqo_normalizado'], copy_dataset['od_normalizado'], color='green')\n",
    "plt.xlabel('DQO')\n",
    "plt.ylabel('Oxígeno Disuelto (OD)')\n",
    "plt.title('Relación entre OD y DQO')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la correlación de Pearson entre las dos columnas\n",
    "correlacion = copy_dataset['dqo_normalizado'].corr(copy_dataset['od_normalizado'])\n",
    "print(f\"Coeficiente de Correlación de Pearson: {correlacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVANDO EL GRAFICO Y USANDO EL COEFICIENTE DE PEARSON: Correlación muy débil o inexistente. Casi no hay relación lineal entre las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EN CONCLUSION, SOLAMENTE EXISTE UNA RELACION LINEAL CLARA ENTRE EL \"OXIGENO DISUELTO Y EL PH\", AUNQUE NO ES FUERTE Y PRECISA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos que el DBO_MG_L era la demanda biológica de oxígeno en miligramos por litro (mg/L), que mide la cantidad de oxígeno requerido por microorganismos para descomponer materia orgánica, y que en valores bastante altos, el agua podria estar recibiendo grandes cantidades de materia orgánica, posiblemente debido a descargas de aguas residuales, desechos industriales o actividad agrícola.\n",
    "\n",
    "veremos con que variable podria estar potencialmente relacionada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "antes que nada borrar viejas columnas creadas para normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset = copy_dataset.drop(['dbo_normalizado', 'ph_normalizado', 'od_normalizado','dqo_normalizado','tem_agua_norm','tem_aire_norm','turbiedad_normalizado','ica_norm'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbo_correlation = copy_dataset.corr(numeric_only=True)[\"dbo_mg_l\"].drop(\"dbo_mg_l\")\n",
    "sorted_correlations = dbo_correlation.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid(True)\n",
    "sns.barplot(x=sorted_correlations.values, y=sorted_correlations.index)\n",
    "plt.title('Correlaciones de la Demanda Biológica de Oxígeno (DBO) con Otras Variables')\n",
    "plt.xlabel('Correlación')\n",
    "plt.ylabel('')\n",
    "plt.xlim([-1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que se tiene una correlacion bastante alta con fosfo_ortofos, entonces vamos a visualizar la relacion que tienen a traves de un Scatter-Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "dbo_dataset = copy_dataset[\"dbo_mg_l\"]\n",
    "fosf_dataset = copy_dataset[\"fosf_ortofos_mg_l\"]\n",
    "\n",
    "stat,p = shapiro(dbo_dataset)\n",
    "print(f\"Test de Shapiro-Wilk para la variable dbo: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "stat,p = shapiro(fosf_dataset)\n",
    "print(f\"Test de Shapiro-Wilk para la variable fosf: Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El test de Shapiro-Wilk nos dice que ninguna de las dos variables sigue una distribucion normal\n",
    "\n",
    "Por lo tantos haremos pruebas no parametricas,pero para ello veremos si tienen homocedasticidad primero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "stat, p = levene(dbo_correlation, fosf_dataset)\n",
    "print(f\"Test de Levene para la Homocedasticidad: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que son homocedasticas, por lo tanto ya probamos que las variables no son normales y vimos que su distribucion es homocedasticas entonces podemos utilizar un test de Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Calcular la correlación de Spearman\n",
    "correlacion, p_valor = spearmanr(copy_dataset[\"dbo_mg_l\"], copy_dataset[\"fosf_ortofos_mg_l\"])\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Coeficiente de correlación de Spearman: {correlacion:.4f}\")\n",
    "print(f\"P-valor: {p_valor:.4f}\")\n",
    "\n",
    "# Interpretación del p-valor\n",
    "if p_valor < 0.05:\n",
    "    print(\"La correlación es significativa.\")\n",
    "else:\n",
    "    print(\"No hay evidencia suficiente para afirmar que la correlación es significativa.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis de correlación de Spearman realizado entre las variables dbo_mg_l y fosf_ortofos_mg_l arrojó un coeficiente de 0.4130 indicando una correlación positiva moderada entre ambas. Además, el p-valor obtenido fue 0.0000, lo que confirma que esta correlación es estadísticamente significativa (p < 0.05). Por lo tanto, se puede concluir que existe una relación significativa entre las concentraciones de DBO y fosfatos ortofosfatos en el dataset.#Elegir entre esta conclusion o la de abajo\n",
    "\n",
    "Como vemos nuestro p-valor es menos que nuestro nivel de significancia(0.5) entonces rechazamos nuestra hipotesis nula y vemos que la concentracion de fosforo ortofosfato no implica una mayor demanda de biologica de oxigeno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipótesis 5: La presencia de materia orgánica suspendida está asociada con un aumento en los niveles de Demanda Biológica de Oxígeno  (DBO) y Demanda Química de Oxígeno (DQO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicio HIPOTESIS 5\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear el boxplot \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=\"mat_susp\", y=\"dbo_mg_l\", data=copy_dataset, notch=True)\n",
    "# Agregar etiquetas a los ejes\n",
    "plt.xlabel(\"Materia Organica Suspendida\")\n",
    "plt.ylabel(\"DBO (mg/l)\")\n",
    "# Agregar un título al gráfico\n",
    "plt.title(\"Relación entre Materia Orgánica Suspendida y DBO\")\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n",
    "\n",
    "# Crear el boxplot \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=\"mat_susp\", y=\"dqo_mg_l\", data=copy_dataset, notch=True)\n",
    "# Agregar etiquetas a los ejes\n",
    "plt.xlabel(\"Materia Organica Suspendida\")\n",
    "plt.ylabel(\"DQO (mg/l)\")\n",
    "# Agregar un título al gráfico\n",
    "plt.title(\"Relación entre Materia Orgánica Suspendida y DQO\")\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separamos los datos en dos grupos\n",
    "DBO_con_mat_susp = copy_dataset[copy_dataset['mat_susp'] == 1]['dbo_mg_l']\n",
    "DBO_sin_mat_susp = copy_dataset[copy_dataset['mat_susp'] == 0]['dbo_mg_l']\n",
    "\n",
    "# Test de Shapiro-Wilk \n",
    "stat, p = shapiro(DBO_con_mat_susp)\n",
    "print(f\"Test de Shapiro-Wilk para muestras con materia organica suspendida (DBO): Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "# Test de Shapiro-Wilk\n",
    "stat, p = shapiro(DBO_sin_mat_susp)\n",
    "print(f\"Test de Shapiro-Wilk para muestras sin materia organica suspendida (DBO): Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Test de Shapiro-Wilk da que no hay normalidad. Debemos descartar la posibilidad de realizar un test T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# QQ plot DBO CON mat_susp\n",
    "stats.probplot(DBO_con_mat_susp, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ Plot para DBO en muestras con materia suspendida\")\n",
    "plt.show()\n",
    "\n",
    "# QQ plot DBO SIN mat_susp\n",
    "stats.probplot(DBO_sin_mat_susp, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ Plot para DBO en muestras sin materia suspendida\")\n",
    "plt.show()\n",
    "\n",
    "# QQ plot DQO CON mat_susp\n",
    "stats.probplot(DQO_con_mat_susp, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ Plot para DQO en muestras con materia suspendida\")\n",
    "plt.show()\n",
    "\n",
    "# QQ plot DQO SIN mat_susp\n",
    "stats.probplot(DQO_sin_mat_susp, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ Plot para DQO en muestras sin materia suspendida\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de Levene para validar homocesticidad\n",
    "stat, p = stats.levene(DBO_con_mat_susp, DBO_sin_mat_susp)\n",
    "print(f\"Test de Levene (DBO): Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Test de Levene para validar homocesticidad\n",
    "stat, p = stats.levene(DQO_con_mat_susp, DQO_sin_mat_susp)\n",
    "print(f\"Test de Levene (DQO): Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para validar la homocedasticidad de varianzas realizamos un test de Levene.  Levene: la hipótesis nula es que las varianzas son significativamente diferentes entre sí (hay heterocedasticidad), por lo que pedimos que el test nos de un p-valor mayor a 0.05 para homocedasticidad. Nos dio como resultado, 0.661 y 0.577 que son mayores a 0.05, así que hay homocedasticidad de los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cumple con el requisito de homocedasticidad pero no normalidad, podemos hacer test de Mann Whitney U. Si el p-valor del test nos da por debajo del umbral de significancia, efectivam ente hay una diferencia significativa entre ambos grupos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de Mann-Whitney U para DBO\n",
    "stat, p = stats.mannwhitneyu(DBO_con_mat_susp, DBO_sin_mat_susp)\n",
    "print(f\"Test de Mann-Whitney U para dbo_mg_l: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Interpretación de los resultados\n",
    "alpha = 0.05  # Nivel de significancia\n",
    "if p > alpha:\n",
    "    print(\"No hay suficiente evidencia para rechazar la hipótesis nula.\")\n",
    "    print(\"No hay una diferencia significativa en el DBO entre muestras con materia organica suspendida y sin materia organica suspendida\")\n",
    "else:\n",
    "    print(\"Se rechaza la hipótesis nula.\")\n",
    "    print(\"Existe una diferencia significativa en el DBO entre muestras con materia organica suspendida y sin materia orgánica suspendida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para DBO obtuvimos un p valor de 0.938, que es muchísimo mayor al umbral de significancia 0.05.   Para DQO nos dio 0.512, lo que indica que las diferencias de DBO/DQO con o sin materia suspendida, no son significativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de Mann-Whitney U para DQO\n",
    "stat, p = stats.mannwhitneyu(DQO_con_mat_susp, DQO_sin_mat_susp)\n",
    "print(f\"Test de Mann-Whitney U para dqo_mg_l: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Interpretación de los resultados\n",
    "alpha = 0.05  # Nivel de significancia\n",
    "if p > alpha:\n",
    "    print(\"No hay suficiente evidencia para rechazar la hipótesis nula.\")\n",
    "    print(\"No hay una diferencia significativa en el DQO entre muestras con materia organica suspendida y sin materia organica suspendida\")\n",
    "else:\n",
    "    print(\"Se rechaza la hipótesis nula.\")\n",
    "    print(\"Existe una diferencia significativa en el DQO entre muestras con materia organica suspendida y sin materia orgánica suspendida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos decir que nuestra hipótesis se rechaza, y por lo tanto no podemos afirmar que la presencia de materia orgánica suspendida está asociada con un aumento en los niveles de Demanda Biológica de Oxígeno  (DBO) y Demanda Química de Oxígeno (DQO), al menos en nuestro conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipótesis 6: A mayor cantidad de materia suspendida, mayores serán las concentraciones de coliformes fecales, Escherichia coli y enterococos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar realizaremos un PCA con las tres variables de interes para ver si podemos reducir la dimensionalidad, y veamos una gráfica en 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "var_princ = [\"colif_fecales_ufc_100ml\", \"escher_coli_ufc_100ml\",\"enteroc_ufc_100ml\"]\n",
    "coli = copy_dataset[var_princ]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "coli_norm = scaler.fit_transform(coli)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(coli_norm)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "data_pca = pca.transform(coli)\n",
    "\n",
    "# Crear una figura y un subplot en 3D\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(data_pca[:, 0], data_pca[:, 1], data_pca[:, 2], c='b', marker='o')\n",
    "\n",
    "ax.set_xlabel('Componente Principal 1')\n",
    "ax.set_ylabel('Componente Principal 2')\n",
    "ax.set_zlabel('Componente Principal 3')\n",
    "\n",
    "plt.title('Visualización de PCA con las tres primeras componentes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que no se logra apreciar muy bien en el 3D, asi que analizaremos la varianza explicada.\n",
    "\n",
    "La primera componente explica el 53.37% de la varianza.\n",
    "\n",
    "La segunda componente contribuye con un 29%.\n",
    "\n",
    "La tercera componente explica el 17% restante.\n",
    "\n",
    "Las dos primeras componentes juntas explican el 99.52% de la varianza total. Por lo tanto vamos a realizar un PCA con dos componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficientes de las variables en cada componente principal\n",
    "loadings = pca.components_\n",
    "\n",
    "# Mostrar los loadings\n",
    "for i, var in enumerate(var_princ):\n",
    "    print(f\"{var}: {loadings[:, i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primera componente: estas dos variables son las más influyentes en la primera componente principal.\n",
    "\n",
    "Segunda componente: es la que más contribuye a esta componente.\n",
    "\n",
    "Tercera componente: tiene la mayor contribución negativa en esta componente. Escher_coli_ufc_100ml también tiene un valor significativo, pero con signo positivo. \n",
    "\n",
    "Entonces voy a hacer un pca con las variables mas significativas, colif_fecales_ufc_100ml y escher_coli_ufc_100ml para obtener una representacion mas reducida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos solo las dos variables de interés\n",
    "var_princ_2 = [\"colif_fecales_ufc_100ml\", \"escher_coli_ufc_100ml\"]\n",
    "coli_2 = copy_dataset[var_princ_2]\n",
    "\n",
    "# Estandarización\n",
    "scaler = StandardScaler()\n",
    "coli_2_norm = scaler.fit_transform(coli_2)\n",
    "\n",
    "# PCA con 2 componentes\n",
    "pca_2 = PCA(n_components=2)\n",
    "pca_2.fit(coli_2_norm)\n",
    "\n",
    "# Varianza explicada\n",
    "print(\"Varianza explicada por cada componente principal:\")\n",
    "print(pca_2.explained_variance_ratio_)\n",
    "\n",
    "# Transformación a las componentes principales\n",
    "data_pca_2 = pca_2.transform(coli_2_norm)\n",
    "\n",
    "# Visualización\n",
    "plt.scatter(data_pca_2[:, 0], data_pca_2[:, 1])\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.title('Visualización de PCA con dos variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que estamos en 2D se puede visualizar mejor, vemos que la mayoria de datos están centrados en la parte izquierda del gráfico y podemos ver que existen varios outliers, así que atraves de mahalanobis calcularemos la cantidad de outliers.\n",
    "\n",
    "Ademas podemos analizar las dos componentes principales:\n",
    "\n",
    "Componente Principal 1: Esta componente 'atrapa' el 60.89% de la varianza explicada.\n",
    "\n",
    "Componente Principal 1: Mientras que esta componente 'atrapa' el 39.10% restante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "# Calcular la matriz de covarianza inversa\n",
    "cov_matrix = np.cov(data_pca_2.T)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "\n",
    "# Calcular la distancia de Mahalanobis para cada punto\n",
    "mean_vector = np.mean(data_pca_2, axis=0)\n",
    "distances = [mahalanobis(row, mean_vector, inv_cov_matrix) for row in data_pca_2]\n",
    "\n",
    "# Definir un umbral para outliers\n",
    "threshold = np.percentile(distances, 97.5)\n",
    "outliers = np.where(distances > threshold)[0]\n",
    "\n",
    "print(f\"Indices de outliers: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_pca_2[:, 0], data_pca_2[:, 1], label=\"Datos normales\")\n",
    "plt.scatter(data_pca_2[outliers, 0], data_pca_2[outliers, 1], color='red', label=\"Outliers\")\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.title('Identificación de Outliers en PCA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que mahanalobis nos dio que existen 4 outliers, entonces vamos a eliminarlo ya que nos generan ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia de los datos sin los outliers\n",
    "copy_dataset_cleaned = copy_dataset.drop(index=copy_dataset.index[outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Variables originales estandarizadas\n",
    "scaler = StandardScaler()\n",
    "coli_2_norm = scaler.fit_transform(copy_dataset[[\"colif_fecales_ufc_100ml\", \"escher_coli_ufc_100ml\"]])\n",
    "\n",
    "# PCA inicial para detectar outliers\n",
    "pca = PCA(n_components=2)\n",
    "data_pca_2 = pca.fit_transform(coli_2_norm)\n",
    "\n",
    "# Detectar outliers\n",
    "threshold = 3\n",
    "outliers = np.where(np.abs(data_pca_2[:, 0]) > threshold)[0]\n",
    "\n",
    "# Eliminar los outliers de los datos estandarizados\n",
    "coli_2_norm_cleaned = np.delete(coli_2_norm, outliers, axis=0)\n",
    "\n",
    "# Aplicar PCA a los datos limpios\n",
    "pca_cleaned = PCA(n_components=2)\n",
    "pca_cleaned.fit(coli_2_norm_cleaned)\n",
    "\n",
    "# Varianza explicada después de eliminar outliers\n",
    "explained_variance_cleaned = pca_cleaned.explained_variance_ratio_\n",
    "\n",
    "# Comparación antes y después\n",
    "varianza_original = [0.52893891, 0.47106109]  # Varianza antes de eliminar outliers\n",
    "varianza_limpia = explained_variance_cleaned\n",
    "\n",
    "# Graficar comparación\n",
    "plt.bar([\"CP1 (original)\", \"CP2 (original)\"], varianza_original, alpha=0.6, label=\"Antes de eliminar outliers\")\n",
    "plt.bar([\"CP1 (limpio)\", \"CP2 (limpio)\"], varianza_limpia, alpha=0.6, label=\"Después de eliminar outliers\")\n",
    "plt.ylabel(\"Porcentaje de varianza explicada\")\n",
    "plt.title(\"Comparación de varianza explicada (PCA)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que luego de la eliminacion de los outlier no cambio mucho, por lo tanto nos quedaremos con ambas componentes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Seleccionar solo las variables que te interesan\n",
    "variables_interes = copy_dataset[['colif_fecales_ufc_100ml', 'escher_coli_ufc_100ml']]\n",
    "\n",
    "# Estandarizar las variables\n",
    "scaler = StandardScaler()\n",
    "original_data_cleaned = scaler.fit_transform(variables_interes)\n",
    "\n",
    "# Obtener los loadings (pesos de las variables en cada componente)\n",
    "loadings = pd.DataFrame(\n",
    "    pca_cleaned.components_,  # Coeficientes de las variables\n",
    "    columns=variables_interes.columns,  # Nombres de las columnas originales\n",
    "    index=[\"Componente Principal 1\", \"Componente Principal 2\"]  # Etiquetas de las componentes\n",
    ")\n",
    "\n",
    "# Mostrar los pesos\n",
    "print(\"Pesos de las variables en las componentes principales:\")\n",
    "print(loadings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del resultado obtenido vemos lo siguiente:\n",
    "\n",
    "Componente Principal 1: Las variables colif_fecales_ufc_100ml y escher_coli_ufc_100ml tienen el mismo peso positivo (0.707) en esta componente, lo que indica que ambas variables tienden a comportarse de manera similar.\n",
    "\n",
    "Componente Principal 2: En esta componente, las variables tienen pesos opuestos (-0.707 para colif_fecales_ufc_100ml y 0.707 para escher_coli_ufc_100ml). Esto sugiere que están en relación inversa: cuando una variable aumenta, la otra tiende a disminuir.\n",
    "\n",
    "Por lo tanto nos quedaremos con ambas variables para el testeo de la hipotesis, pero antes que eso analizaremos su correlacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las columnas de interés\n",
    "var_interes = [\"mat_susp\", \"colif_fecales_ufc_100ml\", \"escher_coli_ufc_100ml\"]\n",
    "data_correlacion = copy_dataset[var_interes]\n",
    "\n",
    "# Calcular la matriz de correlación\n",
    "correlacion = data_correlacion.corr()\n",
    "\n",
    "# Mostrar la matriz de correlación\n",
    "print(correlacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La materia suspendida tiene una correlación débil con E. coli (0.213), pero es casi nula con los coliformes fecales (0.069). Esto sugiere que la relación esperada entre materia suspendida y los indicadores microbiológicos podría no ser tan fuerte o directa como se anticipaba en la hipótesis.\n",
    "\n",
    "Vamos a ver que nos dice el test de hipotesis, para ello utilizaremos el test. Pero primero veamos si son normales haciendo un test de Shapiro-Wilks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "variables = [\"mat_susp\", \"colif_fecales_ufc_100ml\", \"escher_coli_ufc_100ml\"]\n",
    "for var in variables:\n",
    "    stat, p = shapiro(copy_dataset[var])\n",
    "    print(f\"Test de Shapiro-Wilks para la variable {var}: estadístico={stat:.4f}, p-valor={p:.4f}\")\n",
    "    if p < 0.05:\n",
    "        print(f\"La variable {var} no sigue una distribución normal.\")\n",
    "    else:\n",
    "        print(f\"La variable {var} sigue una distribución normal.\")\n",
    "    print(f\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vemos que para los 2 primeros indicadores no sigue una distribucion normal, pero para la tercera si \"escher_coli_ufc_100ml\". Test de correlación de Pearson. Este test evalúa si existe una relación lineal entre dos variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Calcular el coeficiente de correlación de Pearson\n",
    "corr_coefficient, p_value = pearsonr(copy_dataset['escher_coli_ufc_100ml'], copy_dataset['mat_susp'])\n",
    "\n",
    "# Interpretación\n",
    "if p_value < 0.05:\n",
    "    print(\"Rechazamos la hipótesis nula: Hay una correlación significativa\")\n",
    "else:\n",
    "    print(\"No rechazamos la hipótesis nula: No hay correlación significativa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos una correlacion significativa entre materia suspendida y ESCHER_COLI_UFC_100ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ccontinuamos con las otras que no siguen una distribucion normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "# Realizar el test de Levene para las tres variables\n",
    "stat, p = levene(copy_dataset[\"mat_susp\"], copy_dataset[\"colif_fecales_ufc_100ml\"])\n",
    "\n",
    "print(f\"Test de Levene: estadístico={stat:.4f}, p-valor={p:.4f}\")\n",
    "\n",
    "# Interpretación del p-valor\n",
    "if p < 0.05:\n",
    "    print(\"Las varianzas no son homogéneas (no se cumple la homocedasticidad).\")\n",
    "else:\n",
    "    print(\"Las varianzas son homogéneas (se cumple la homocedasticidad).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo que no tenemos normalidad y tampoco tenemos homocedasticidad, entonces vamos a tener que utilizar el test de Kruskal-Wallis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stat, p = stats.kruskal(copy_dataset[\"mat_susp\"], copy_dataset[\"colif_fecales_ufc_100ml\"])\n",
    "print(f\"Test de Kruskal-Wallis para la materia suspendida: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Interpretación de los resultados\n",
    "alpha = 0.05  # Nivel de significancia\n",
    "if p > alpha:\n",
    "    print(\"No hay suficiente evidencia para rechazar la hipótesis nula.\")\n",
    "    print(\"Hay diferencias significativas entre las medianas de las variables.\")\n",
    "else:\n",
    "    print(\"Se rechaza la hipótesis nula.\")\n",
    "    print(\"No hay diferencias significativas entre las medianas de las variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El test de Kruskal-Wallis ha mostrado que existen diferencias significativas entre las distribuciones de las variables, lo que sugiere que la concentracion de materia suspendida, coliformes fecales y enterococos tienen comportamientos diferentes en términos de sus distribuciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicoespecialvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
